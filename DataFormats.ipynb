{"cells":[{"cell_type":"code","source":["## Helper to display filesize\ndef readable_size(num, suffix='B'):\n    for unit in ['','K','M','G','T','P','E','Z']:\n        if abs(num) < 1024.0:\n            return \"%3.1f%s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n  \n# Helper to get total distributed filesize\ndef sizeof(path):\n  return sum([f.size for f in dbutils.fs.ls(path)])\n\n# Query\ndef nationkey_query(df):\n  return df.agg({\"nationkey\": \"sum\"}).collect()\n\ndef measure_performance(df):\n  import time\n  start = time.perf_counter()\n  nationkey_query(df)\n  end = time.perf_counter()\n  return (end-start)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Step 1\n# Import from tbl file\ndf = spark.read.csv(\"/FileStore/tables/customer.tbl\", header=True, mode=\"PERMISSIVE \", sep=\"|\", inferSchema = True)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Export as csv\ncsv_name = \"/FileStore/tables/customer.csv\"\ndbutils.fs.rm(csv_name, True)\ndf.write.csv(csv_name, header=True)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Use ls to check filesize (24304318 bytes or aprox 23 MB)\ncsv_size = readable_size(sizeof(csv_name))\nprint(\"CSV Size: \" + csv_size)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">CSV Size: 23.2MB\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Measure performance once\ntime = measure_performance(spark.read.csv(csv_name, inferSchema=True, header=True))\nprint(\"%.2gs\" % time)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1s\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Step 2: Store as parquet\npq_name = \"/FileStore/tables/customer.pq\"\ndbutils.fs.rm(pq_name, True)\ndf.write.parquet(pq_name)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Use ls to check filesize (24304318 bytes or aprox 12 MB)\npq_size = readable_size(sizeof(pq_name))\nprint(\"Parquet Size: \" + pq_size)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Parquet Size: 11.9MB\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# How is the file stored\ndisplay(dbutils.fs.ls(pq_name))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/customer.pq/_SUCCESS</td><td>_SUCCESS</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/_committed_1911199852581842293</td><td>_committed_1911199852581842293</td><td>624</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/_started_1911199852581842293</td><td>_started_1911199852581842293</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/part-00000-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-567-1-c000.snappy.parquet</td><td>part-00000-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-567-1-c000.snappy.parquet</td><td>2165843</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/part-00001-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-568-1-c000.snappy.parquet</td><td>part-00001-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-568-1-c000.snappy.parquet</td><td>2157026</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/part-00002-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-569-1-c000.snappy.parquet</td><td>part-00002-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-569-1-c000.snappy.parquet</td><td>2156774</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/part-00003-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-570-1-c000.snappy.parquet</td><td>part-00003-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-570-1-c000.snappy.parquet</td><td>2158091</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/part-00004-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-571-1-c000.snappy.parquet</td><td>part-00004-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-571-1-c000.snappy.parquet</td><td>2149026</td></tr><tr><td>dbfs:/FileStore/tables/customer.pq/part-00005-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-572-1-c000.snappy.parquet</td><td>part-00005-tid-1911199852581842293-0f1cc739-b67a-4e55-9517-52b3bf77723b-572-1-c000.snappy.parquet</td><td>1728176</td></tr></tbody></table></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Measure performance once\ntime = measure_performance(spark.read.parquet(pq_name))\nprint(\"%.2gs\" % time)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.81s\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Step 3\n\ndf_csv = spark.read.csv(csv_name, inferSchema=True, header=True)\ncsv_timings = [measure_performance(df_csv) for i in range(10)]\n\ndf_pq = spark.read.parquet(pq_name)\npq_timings = [measure_performance(df_pq) for i in range(10)]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["from pyspark.sql.types import *\n\nschema = StructType([StructField(\"executionTime\", DoubleType())])\ndf_csv_perf = spark.createDataFrame([(val,) for val in csv_timings],schema=schema) \ndf_pq_perf = spark.createDataFrame([(val,) for val in pq_timings],schema=schema) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["df_csv_perf.describe(\"executionTime\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-------------------+\nsummary|      executionTime|\n+-------+-------------------+\n  count|                 10|\n   mean| 0.8861977789987577|\n stddev|0.23012800217383433|\n    min| 0.6919168140011607|\n    max|  1.476315196006908|\n+-------+-------------------+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["df_pq_perf.describe(\"executionTime\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+------------------+\nsummary|     executionTime|\n+-------+------------------+\n  count|                10|\n   mean|0.7257327040017116|\n stddev| 0.099121348284065|\n    min|0.6063944229972549|\n    max| 0.913615094992565|\n+-------+------------------+\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# plot\nimport pandas as pd\n\nd1 = {'csv': csv_timings, 'pq': pq_timings}\ndf1 = pd.DataFrame(data=d1)\ndisplay(df1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>csv</th><th>pq</th></tr></thead><tbody><tr><td>0.9522031300002709</td><td>0.7203724800056079</td></tr><tr><td>0.8506693800009089</td><td>0.913615094992565</td></tr><tr><td>0.7230256689945236</td><td>0.7275070559990127</td></tr><tr><td>0.6919168140011607</td><td>0.7240587859996594</td></tr><tr><td>0.7049983789911494</td><td>0.6063944229972549</td></tr><tr><td>0.7547447359975195</td><td>0.6825149730138946</td></tr><tr><td>0.8725909189961385</td><td>0.7291782480024267</td></tr><tr><td>0.8624752629984869</td><td>0.6606658320088172</td></tr><tr><td>1.476315196006908</td><td>0.8727490029996261</td></tr><tr><td>0.9730383040005108</td><td>0.6202711439982522</td></tr></tbody></table></div>"]}}],"execution_count":14},{"cell_type":"code","source":["import random\nfrom numpy import ndarray\nimport numpy as np\n\n# helpers\ndef range_query(df):\n  return df.agg({\"c1\": \"sum\"}).collect()\n\ndef measure_range_performance(df):\n  import time\n  start = time.perf_counter()\n  range_query(df)\n  end = time.perf_counter()\n  return (end-start)\n\n# generate random dataframe\nheader= []\nfor i in range(10):\n  header.append(\"c\" + str(i+1))\n  \ndf = pd.DataFrame(np.random.random(size=(1000000,10)), columns=header)\ndf = spark.createDataFrame(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["# step1\n# export as csv\ncsv_name = \"/FileStore/tables/random.csv\"\ndbutils.fs.rm(csv_name, True)\ndf.write.csv(csv_name, header=True)\n\n# get csv size\ncsv_size = readable_size(sizeof(csv_name))\nprint(\"CSV Size: \" + csv_size)\n\n# measure performance\ntime = measure_range_performance(spark.read.csv(csv_name, inferSchema=True, header=True))\nprint(\"%.2gs\" % time)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">CSV Size: 183.8MB\n4.4s\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["# step2\n\n# export as parquet\npq_name = \"/FileStore/tables/random.pq\"\ndbutils.fs.rm(pq_name, True)\ndf.write.parquet(pq_name)\n\n# get csv size\npq_size = readable_size(sizeof(pq_name))\nprint(\"Parquet Size: \" + pq_size)\n\n# measure performance\ntime = measure_range_performance(spark.read.parquet(pq_name))\nprint(\"%.2gs\" % time)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Parquet Size: 76.3MB\n0.99s\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# Business Data\n\n# CSV Size: 23.2MB\n# Parquet Size: 11.9MB\n# CSV mean over execution time: 0.8861977789987577\n# Parquet mean over execution time: 0.7257327040017116\n\n# Scientific Data\n\n# CSV Size: 183.8MB\n# 4.4s\n# Parquet Size: 76.3MB\n# 0.99s\n\n# Difference in Size for Business Data: Parquet 51.3% of csv size\n# Difference in Querytime for Business Data: Parquet only needs 81.9% of csv querytime\n\n# Difference in Size for Scientific Data: Parquet is 41.5% of csv size\n# Difference in Querytime for Scientific Data: Parquet only needs 22.5% of csv querytime\n\n# Querytime is significantly faster if file size increases by factor of 10\n# Measurements agree with expected behaviour\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["import time\n\n# Exercise 1\ndf = spark.read.csv(\"/FileStore/tables/customer.tbl\", header=True, mode=\"PERMISSIVE \", sep=\"|\", inferSchema = True)\nname = \"/FileStore/tables/customer\"\ndbutils.fs.rm(name, True)\ndf.write.format(\"delta\").save(name)\nspark.sql(\"CREATE TABLE IF NOT EXISTS customer USING DELTA LOCATION '/FileStore/tables/customer'\")\n\nstart = time.perf_counter()\nspark.sql(\"SELECT SUM(nationkey) FROM customer\")\nend = time.perf_counter()\nduration = end-start\nprint(\"%.2gs\" % duration)\n\n# Exercise 2\nheader= []\nfor i in range(10):\n  header.append(\"c\" + str(i+1))\n  \ndf = pd.DataFrame(np.random.random(size=(1000000,10)), columns=header)\ndf = spark.createDataFrame(df)\n\nname = \"/FileStore/tables/scientific\"\ndbutils.fs.rm(name, True)\ndf.write.format(\"delta\").save(name)\n\nspark.sql(\"CREATE TABLE IF NOT EXISTS scientific USING DELTA LOCATION '/FileStore/tables/scientific'\")\n\nstart = time.perf_counter()\nspark.sql(\"SELECT SUM(c1) FROM scientific\")\nend = time.perf_counter()\nduration = end-start\nprint(\"%.2gs\" % duration)\n\n# -> delta tables are even more efficient"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.17s\n0.19s\n</div>"]}}],"execution_count":19}],"metadata":{"name":"Exercise2","notebookId":4466189294007422},"nbformat":4,"nbformat_minor":0}
